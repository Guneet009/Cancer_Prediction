- Best Parameters:
    n_jobs: -1
    penalty: l2
    solver: saga
    verbose: 0
  Model: Logistic_Regression
  Test Evaluation: !!python/object:src.entity.artifact_entity.ModelTrainerMetric
    f1_score: 0.961038961038961
    precision_score: 0.9736842105263158
    recall_score: 0.9487179487179487
  Train Evaluation: !!python/object:src.entity.artifact_entity.ModelTrainerMetric
    f1_score: 0.9824561403508771
    precision_score: 0.9940828402366864
    recall_score: 0.9710982658959537
- Best Parameters:
    criterion: log_loss
    max_features: sqrt
    n_estimators: 32
    n_jobs: -1
    verbose: 0
  Model: Random_Forest
  Test Evaluation: !!python/object:src.entity.artifact_entity.ModelTrainerMetric
    f1_score: 0.9620253164556962
    precision_score: 0.95
    recall_score: 0.9743589743589743
  Train Evaluation: !!python/object:src.entity.artifact_entity.ModelTrainerMetric
    f1_score: 1.0
    precision_score: 1.0
    recall_score: 1.0
- Best Parameters:
    colsample_bytree: 0.8
    gamma: 0.1
    learning_rate: 0.1
    max_depth: 3
    subsample: 0.9
  Model: XGBoost
  Test Evaluation: !!python/object:src.entity.artifact_entity.ModelTrainerMetric
    f1_score: 0.961038961038961
    precision_score: 0.9736842105263158
    recall_score: 0.9487179487179487
  Train Evaluation: !!python/object:src.entity.artifact_entity.ModelTrainerMetric
    f1_score: 1.0
    precision_score: 1.0
    recall_score: 1.0
